{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Classifier Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repo goes through a tutorial on how to create your own classifier using Twitter data\n",
    "\n",
    "Tutor followed: http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of words with positive sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = [('I love this car', 'positive'),\n",
    "              ('This view is amazing', 'positive'),\n",
    "              ('I feel great this morning', 'positive'),\n",
    "              ('I am so excited about the concert', 'positive'),\n",
    "              ('He is my best friend', 'positive')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of words with negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tweets = [('I do not like this car', 'negative'),\n",
    "              ('This view is horrible', 'negative'),\n",
    "              ('I feel tired this morning', 'negative'),\n",
    "              ('I am not looking forward to the concert', 'negative'),\n",
    "              ('He is my enemy', 'negative')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take both of those lists and create a single list of tuples each containing two elements. First element is an array containing the words and second element is the type of sentiment. We get rid of the words smaller than 2 characters and we use lowercase for everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['love', 'this', 'car'], 'positive'),\n",
       " (['this', 'view', 'amazing'], 'positive'),\n",
       " (['feel', 'great', 'this', 'morning'], 'positive'),\n",
       " (['excited', 'about', 'the', 'concert'], 'positive'),\n",
       " (['best', 'friend'], 'positive'),\n",
       " (['not', 'like', 'this', 'car'], 'negative'),\n",
       " (['this', 'view', 'horrible'], 'negative'),\n",
       " (['feel', 'tired', 'this', 'morning'], 'negative'),\n",
       " (['not', 'looking', 'forward', 'the', 'concert'], 'negative'),\n",
       " (['enemy'], 'negative')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for (words, sentiment) in pos_tweets + neg_tweets:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 3] \n",
    "    tweets.append((words_filtered, sentiment))\n",
    "    \n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test tweets\n",
    "test_tweets = [\n",
    "    (['feel', 'happy', 'this', 'morning'], 'positive'),\n",
    "    (['larry', 'friend'], 'positive'),\n",
    "    (['not', 'like', 'that', 'man'], 'negative'),\n",
    "    (['house', 'not', 'great'], 'negative'),\n",
    "    (['your', 'song', 'annoying'], 'negative')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of word features need to be extracted from the tweets. It is a list with every distinct words ordered by frequency of appearance. We use the following function to get the list plus the two helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)    \n",
    "    word_features = wordlist.keys()\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        all_words.extend(words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = get_word_features(get_words_in_tweets(tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a classifier, we need to decide what features are relevant. To do that, we first need a `feature extractor`. The one we are going to use returns a dictionary indicating what words are contained in the input passed. Here, the input is the tweet. We use the word features list defined above along with the input to create the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['love', 'this', 'car'], 'positive'),\n",
       " (['this', 'view', 'amazing'], 'positive'),\n",
       " (['feel', 'great', 'this', 'morning'], 'positive'),\n",
       " (['excited', 'about', 'the', 'concert'], 'positive'),\n",
       " (['best', 'friend'], 'positive'),\n",
       " (['not', 'like', 'this', 'car'], 'negative'),\n",
       " (['this', 'view', 'horrible'], 'negative'),\n",
       " (['feel', 'tired', 'this', 'morning'], 'negative'),\n",
       " (['not', 'looking', 'forward', 'the', 'concert'], 'negative'),\n",
       " (['enemy'], 'negative')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our feature extractor, we can apply the features to our classifier using the method apply_features. We pass the feature extractor along with the tweets list defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `training_set` contains the labeled feature sets. It is a list of tuples which each tuple containing the feature dictionary and the sentiment string for each tweet. The sentiment string is also called ‘label’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains(about)': False,\n",
       "  'contains(amazing)': False,\n",
       "  'contains(best)': False,\n",
       "  'contains(car)': False,\n",
       "  'contains(concert)': False,\n",
       "  'contains(enemy)': False,\n",
       "  'contains(excited)': False,\n",
       "  'contains(feel)': False,\n",
       "  'contains(forward)': False,\n",
       "  'contains(friend)': False,\n",
       "  'contains(great)': False,\n",
       "  'contains(horrible)': True,\n",
       "  'contains(like)': False,\n",
       "  'contains(looking)': False,\n",
       "  'contains(love)': False,\n",
       "  'contains(morning)': False,\n",
       "  'contains(not)': False,\n",
       "  'contains(the)': False,\n",
       "  'contains(this)': True,\n",
       "  'contains(tired)': False,\n",
       "  'contains(view)': True},\n",
       " 'negative')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Algorithm\n",
    "\n",
    "The Naive Bayes classifier uses the prior probability of each label which is the frequency of each label in the training set, and the contribution from each feature. In our case, the frequency of each label is the same for ‘positive’ and ‘negative’. The word ‘amazing’ appears in 1 of 5 of the positive tweets and none of the negative tweets. This means that the likelihood of the ‘positive’ label will be multiplied by 0.2 when this word is seen as part of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "           contains(not) = False          positi : negati =      1.6 : 1.0\n",
      "          contains(love) = False          negati : positi =      1.2 : 1.0\n",
      "        contains(friend) = False          negati : positi =      1.2 : 1.0\n",
      "       contains(forward) = False          positi : negati =      1.2 : 1.0\n",
      "          contains(like) = False          positi : negati =      1.2 : 1.0\n",
      "       contains(looking) = False          positi : negati =      1.2 : 1.0\n",
      "         contains(great) = False          negati : positi =      1.2 : 1.0\n",
      "         contains(about) = False          negati : positi =      1.2 : 1.0\n",
      "         contains(tired) = False          positi : negati =      1.2 : 1.0\n",
      "      contains(horrible) = False          positi : negati =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Print the most informative features using this function\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our classifier initialized, we can try to classify a tweet and see what the sentiment type output is. Our classifier is able to detect that this tweet has a positive sentiment because of the word ‘friend’ which is associated to the positive tweet ‘He is my best friend’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = 'Larry is not my friend'\n",
    "classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.4939}\n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "ss = sid.polarity_scores(tweet)\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working within nltk:\n",
    "#     print extract_features(tweet.split())\n",
    "# {'contains(not)': False,\n",
    "#  'contains(view)': False,\n",
    "#  'contains(best)': False,\n",
    "#  'contains(excited)': False,\n",
    "#  'contains(morning)': False,\n",
    "#  'contains(about)': False,\n",
    "#  'contains(horrible)': False,\n",
    "#  'contains(like)': False,\n",
    "#  'contains(this)': False,\n",
    "#  'contains(friend)': True,       --This is why positive\n",
    "#  'contains(concert)': False,\n",
    "#  'contains(feel)': False,\n",
    "#  'contains(love)': False,\n",
    "#  'contains(looking)': False,\n",
    "#  'contains(tired)': False,\n",
    "#  'contains(forward)': False,\n",
    "#  'contains(car)': False,\n",
    "#  'contains(the)': False,\n",
    "#  'contains(amazing)': False,\n",
    "#  'contains(enemy)': False,\n",
    "#  'contains(great)': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`def classify(self, featureset):`\n",
    "\n",
    "-    Discard any feature names that we've never seen before.\n",
    "-    Find the log probability of each label, given the features.\n",
    "-    Then add in the log probability of features given labels.\n",
    "-    Generate a probability distribution dictionary using the dict logprod\n",
    "-    Return the sample with the greatest probability from the probability distribution dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
